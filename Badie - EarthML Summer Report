Joining Earth-ML has been the unique marker of the summer of 2020. Within a period filled with some uncertainties, and perhaps several difficulties, this summer has been
the most productive and fruitful period of perhaps my life. By its very early stages, I was still new to many stuff: I haven’t had the chance to closely interact with any of 
my classmates before, I was new to working in a group (in a virtual environment), still fresh to Python thanks to PHYS198, not to mention knowing almost nothing about machine
learning and seismology “stuff”. It seemed like a dangerous idea at that instant to join the group with such a blurry background, much like going into the void, but it was an 
intriguing one. It turned out that this very concept embodies the theme of this project: acquiring enough courage to delve into and work on the topics you know nothing about. 

One key lesson I learned is that I’m, and others are, capable of addressing and studying topics much regarded as “above our level”. I personally was able to learn about 
Seismology, Machine Learning, Neural Networks, Python libraries like ObsPy and TensorFlow, signal analysis and preprocessing techniques, Fourier Transforms, Wavelet Transforms,
STA/LTA algorithms, Linux Command Line, not to mention skills like being passionate with errors and calmly debugging :) with only a semester of education at Bogazici. I have 
as well developed a passion for signals and applying techniques to extract useful insight from seemingly chaotic data (filtering, tapering, denoising, etc.). 

No good experience passes by without committing errors, and I have to confess I regret falling into many such: I haven’t kept up with our meetings on a regular basis near 
the end of this period; I haven’t been open enough to share my difficulties with others and ask for help and instruction when needed; I failed to some point in opening up 
to new research mates and making stronger connections with several friends; and I often had much hesitation when joining new tasks which I had no previous background in. 



Below is a timeline of the main tasks I have joined throughout the first stage of this research, with key encounters and experiences listed as points:

1- Literature Search: 
- Reading & Summarizing more than 40 research papers
- Learning about neural networks & seismology terms and concepts
- Creating 3 GitHub WikiPages (Earthquake Detection ML - Denoising - Seismology) with brief summaries.


2- Learning and Working with GitHub:
- Pull Requests 
- Forking 
- Uploading Files and Notebooks


3- Presenting STEAD Paper:
- First Group-Based Task
- First Presentation


4- Wavelet Transforms of Seismograms 
- First encounter with Jupyter Notebooks and Anaconda 
- First encounter with ObsPy and PyWavelets
- New Scipy Commands
- Downloading Waveform and Instrument Response Data from Kandilli
- Applying Preprocessing to Data (Filtering - Denoising - Tapering - Removing Instrument Response)
- Learning about Wavelets and Wavelets Transforms 
- PPSD Plots and Spectrograms + Analysis 


5- Implementing STA/LTA algorithm on Silivri Dataset using ObsPy
- Further ObsPy Experience
- Data Analysis
- Detections and Parameter Tuning 


6- “Selecting a Set of Tasks for ObsPy Learners” Part I & II
- Chance to Review ObsPy
- Chance to Interact with Other Members (and Perhaps Form New Friendships) and Help Some.


7- Learning about Fourier Series and Transforms:
- Basic Concepts Underlying Fourier Series and Transforms (Frequency Domain - Euler's Representation - Fourier Coefficients - FFT and DFT) from Videos, Textbook Chapters, and Webpages
- Creating an Interactive Notebook
- Reviewing SymPy and Matplotlib
- In-Depth Research about Basic Topics
- Developing a Special Interest 


8- Running and Installing ConvNetQuake:
- First encounter with Virtual Machines and Linux OS / Ubuntu
- Linux Command Line & Bash Shell Shortcuts
- Creating and Working with Virtual Environments 
- Cloning a GitHub Repository
- Developing an Insight about Computer Functioning and Hardware Specifications (RAM - GPU - Disks - CPU)
- Installing Specific Versions of Python and Python Libraries 
- Using Python on a Terminal (Windows and Linux)
- Learning about Parallel Computation Concepts through Encounters with CUDA and cuDNN
- Debugging Basics with PDB 


9- Learning Tensorflow 
- CNN Noise Model (Early Stage of Project)
- Tutorials:
  - The Sequential Model 
  - Training and Evaluation
  - Save and Load
  - Basic Image Classification 
  - Basic Text Classification
  - Regression 

I kept on procrastinating in writing this report because I wanted it, to the furthest extent, to embody the feelings of gratefulness and content I have towards Earth-ML. 
With that, I had to write one at some point. One additional thing I learned in this project is that when making a presentation or submitting a piece of work, I should conclude
with the point(s) I care most to deliver to my audience. If one thing is to be taken from this essay, it is that this team is a unique one, and I’m grateful to be part of it!

Badie
26/10/2020
